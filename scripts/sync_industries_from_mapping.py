#!/usr/bin/env python3
"""
ä½¿ç”¨è¡Œä¸šæ˜ å°„è¡¨åŒæ­¥è¡Œä¸šæ•°æ®
å½“AKShare APIä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„è¡Œä¸šæ˜ å°„è¡¨æ¥è¡¥å……è¡Œä¸šæ•°æ®
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import UpdateOne
from app.core.config import settings
import logging
import re

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def get_industry_by_code_pattern(code: str) -> str:
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç æ¨¡å¼æ¨æ–­è¡Œä¸šï¼ˆåŸºäºå¸¸è§è¡Œä¸šåˆ†å¸ƒï¼‰
    è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ˜ å°„ï¼Œå®é™…åº”è¯¥ä»æ•°æ®æºè·å–
    """
    code = str(code).zfill(6)
    
    # é“¶è¡Œç±»ï¼ˆå¸¸è§é“¶è¡Œä»£ç ï¼‰
    bank_codes = ['000001', '600000', '600015', '600016', '600036', '601166', '601169', 
                  '601288', '601328', '601398', '601818', '601838', '601860', '601916',
                  '601939', '601988', '601998', '002142', '002839']
    if code in bank_codes:
        return 'é“¶è¡Œ'
    
    # è¯åˆ¸ç±»ï¼ˆå¸¸è§è¯åˆ¸ä»£ç ï¼‰
    security_codes = ['000166', '000686', '000728', '000750', '000776', '000783', '002500',
                     '002673', '002736', '002797', '600030', '600061', '600109', '600369',
                     '600837', '600909', '600958', '600999', '601066', '601108', '601136',
                     '601162', '601198', '601211', '601236', '601375', '601377', '601456',
                     '601555', '601688', '601788', '601878', '601881', '601901', '601990']
    if code in security_codes:
        return 'è¯åˆ¸'
    
    # ä¿é™©ç±»
    insurance_codes = ['000627', '601318', '601601', '601628', '601319', '601336']
    if code in insurance_codes:
        return 'ä¿é™©'
    
    # æ ¹æ®ä»£ç æ®µæ¨æ–­ï¼ˆç®€åŒ–ç‰ˆï¼‰
    if code.startswith('60'):  # ä¸Šæµ·ä¸»æ¿
        if code.startswith('600519') or code.startswith('000858'):
            return 'é…¿é…’è¡Œä¸š'
        elif code.startswith('600276') or code.startswith('000538'):
            return 'åŒ–å­¦åˆ¶è¯'
        elif code.startswith('600887') or code.startswith('000895'):
            return 'é£Ÿå“é¥®æ–™'
        elif code.startswith('600036') or code.startswith('600000'):
            return 'é“¶è¡Œ'
    elif code.startswith('000'):  # æ·±åœ³ä¸»æ¿
        if code.startswith('000001'):
            return 'é“¶è¡Œ'
        elif code.startswith('000002'):
            return 'æˆ¿åœ°äº§å¼€å‘'
        elif code.startswith('000651') or code.startswith('000333'):
            return 'å®¶ç”µè¡Œä¸š'
        elif code.startswith('000858'):
            return 'é…¿é…’è¡Œä¸š'
    elif code.startswith('300'):  # åˆ›ä¸šæ¿
        if code.startswith('300750'):
            return 'ç”µæ± '
        elif code.startswith('300059'):
            return 'äº’è”ç½‘æœåŠ¡'
        elif code.startswith('300015'):
            return 'åŒ»ç–—æœåŠ¡'
    
    return ''  # æ— æ³•æ¨æ–­æ—¶è¿”å›ç©º


async def sync_industries_from_mapping():
    """ä½¿ç”¨è¡Œä¸šæ˜ å°„è¡¨åŒæ­¥è¡Œä¸šæ•°æ®"""
    logger.info("=" * 80)
    logger.info("ğŸš€ ä½¿ç”¨è¡Œä¸šæ˜ å°„è¡¨åŒæ­¥è¡Œä¸šæ•°æ®")
    logger.info("=" * 80)
    
    # è¿æ¥MongoDB
    logger.info("\nğŸ”Œ è¿æ¥MongoDB...")
    client = AsyncIOMotorClient(settings.MONGO_URI)
    db = client[settings.MONGO_DB]
    collection = db["stock_basic_info"]
    
    try:
        # 1. æŸ¥æ‰¾æ²¡æœ‰è¡Œä¸šæ•°æ®çš„è‚¡ç¥¨
        logger.info("\nğŸ“‹ æ­¥éª¤1: æŸ¥æ‰¾éœ€è¦è¡¥å……è¡Œä¸šæ•°æ®çš„è‚¡ç¥¨...")
        
        # æŸ¥æ‰¾AKShareæ•°æ®æºä¸­æ²¡æœ‰è¡Œä¸šæ•°æ®çš„è‚¡ç¥¨
        query = {
            "source": "akshare",
            "$or": [
                {"industry": {"$exists": False}},
                {"industry": None},
                {"industry": ""}
            ]
        }
        
        stocks_without_industry = await collection.find(
            query,
            {"code": 1, "symbol": 1, "name": 1}
        ).limit(1000).to_list(length=1000)  # é™åˆ¶å¤„ç†1000åªè‚¡ç¥¨
        
        logger.info(f"  æ‰¾åˆ° {len(stocks_without_industry)} åªéœ€è¦è¡¥å……è¡Œä¸šæ•°æ®çš„è‚¡ç¥¨ï¼ˆé™åˆ¶1000åªï¼‰")
        
        if not stocks_without_industry:
            logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨éƒ½å·²æœ‰è¡Œä¸šæ•°æ®")
            return
        
        # 2. å°è¯•ä»AKShareè·å–è¡Œä¸šä¿¡æ¯ï¼ˆå¦‚æœAPIå¯ç”¨ï¼‰
        logger.info("\nğŸ“‹ æ­¥éª¤2: å°è¯•ä»AKShareè·å–è¡Œä¸šä¿¡æ¯...")
        
        import akshare as ak
        
        industry_map = {}
        success_count = 0
        failed_count = 0
        
        # åªå¤„ç†å‰100åªè‚¡ç¥¨ï¼Œé¿å…è¶…æ—¶
        sample_stocks = stocks_without_industry[:100]
        
        for i, stock in enumerate(sample_stocks, 1):
            code = stock.get("code") or stock.get("symbol")
            name = stock.get("name", "")
            
            if not code:
                continue
            
            code = str(code).zfill(6)
            
            # å°è¯•ä»AKShareè·å–
            try:
                def fetch_info():
                    try:
                        return ak.stock_individual_info_em(symbol=code)
                    except:
                        return None
                
                stock_info = await asyncio.to_thread(fetch_info)
                
                if stock_info is not None and not stock_info.empty:
                    # æå–è¡Œä¸šä¿¡æ¯
                    industry_row = stock_info[stock_info['item'] == 'æ‰€å±è¡Œä¸š']
                    if not industry_row.empty:
                        industry = str(industry_row['value'].iloc[0]).strip()
                        if industry and industry not in ['-', '--', 'æœªçŸ¥', '']:
                            industry_map[code] = industry
                            success_count += 1
                            logger.info(f"  âœ… [{i}/{len(sample_stocks)}] {code} ({name}): {industry}")
                            await asyncio.sleep(0.2)  # å»¶è¿Ÿé¿å…é™æµ
                            continue
            except Exception as e:
                # APIè°ƒç”¨å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æ˜ å°„è¡¨
                pass
            
            # å¦‚æœAPIè·å–å¤±è´¥ï¼Œä½¿ç”¨æ˜ å°„è¡¨
            industry = get_industry_by_code_pattern(code)
            if industry:
                industry_map[code] = industry
                logger.info(f"  ğŸ“‹ [{i}/{len(sample_stocks)}] {code} ({name}): {industry} (æ˜ å°„è¡¨)")
            else:
                failed_count += 1
                logger.debug(f"  âš ï¸  [{i}/{len(sample_stocks)}] {code} ({name}): æ— æ³•æ¨æ–­è¡Œä¸š")
            
            await asyncio.sleep(0.1)
        
        logger.info(f"\nâœ… æˆåŠŸè·å– {success_count} åªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯ï¼ˆAPIï¼‰")
        logger.info(f"ğŸ“‹ ä½¿ç”¨æ˜ å°„è¡¨è¡¥å…… {len(industry_map) - success_count} åªè‚¡ç¥¨")
        logger.info(f"âš ï¸  æ— æ³•è·å– {failed_count} åªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯")
        
        if not industry_map:
            logger.warning("âš ï¸  æ²¡æœ‰è·å–åˆ°ä»»ä½•è¡Œä¸šæ•°æ®")
            return
        
        # 3. æ‰¹é‡æ›´æ–°AKShareæ•°æ®æº
        logger.info("\nğŸ’¾ æ­¥éª¤3: æ‰¹é‡æ›´æ–°AKShareæ•°æ®æºçš„è¡Œä¸šæ•°æ®...")
        
        operations = []
        update_count = 0
        batch_size = 100
        
        for code, industry in industry_map.items():
            operations.append(
                UpdateOne(
                    {"code": code, "source": "akshare"},
                    {"$set": {"industry": industry, "updated_at": datetime.utcnow()}},
                    upsert=False
                )
            )
            
            if len(operations) >= batch_size:
                try:
                    result = await collection.bulk_write(operations, ordered=False)
                    update_count += result.modified_count
                    logger.info(f"  å·²æ›´æ–° {update_count} åªè‚¡ç¥¨çš„è¡Œä¸šæ•°æ®...")
                    operations = []
                except Exception as e:
                    logger.warning(f"  æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
                    operations = []
        
        if operations:
            try:
                result = await collection.bulk_write(operations, ordered=False)
                update_count += result.modified_count
            except Exception as e:
                logger.warning(f"  æœ€åä¸€æ‰¹æ›´æ–°å¤±è´¥: {e}")
        
        logger.info(f"âœ… å…±æ›´æ–° {update_count} åªAKShareæ•°æ®æºè‚¡ç¥¨çš„è¡Œä¸šæ•°æ®")
        
        # 4. åŒæ­¥åˆ°TDXæ•°æ®æº
        logger.info("\nğŸ’¾ æ­¥éª¤4: å°†è¡Œä¸šæ•°æ®åŒæ­¥åˆ°TDXæ•°æ®æº...")
        
        tdx_operations = []
        tdx_update_count = 0
        
        for code, industry in industry_map.items():
            # è·å–è‚¡ç¥¨åç§°
            stock_doc = await collection.find_one(
                {"code": code, "source": "akshare"},
                {"name": 1}
            )
            stock_name = stock_doc.get("name", f"è‚¡ç¥¨{code}") if stock_doc else f"è‚¡ç¥¨{code}"
            
            tdx_operations.append(
                UpdateOne(
                    {"code": code, "source": "tdx"},
                    {
                        "$set": {
                            "code": code,
                            "symbol": code,
                            "name": stock_name,
                            "industry": industry,
                            "source": "tdx",
                            "updated_at": datetime.utcnow()
                        }
                    },
                    upsert=True
                )
            )
            
            if len(tdx_operations) >= batch_size:
                try:
                    result = await collection.bulk_write(tdx_operations, ordered=False)
                    tdx_update_count += result.modified_count + result.upserted_count
                    logger.info(f"  å·²åŒæ­¥ {tdx_update_count} æ¡TDXè®°å½•...")
                    tdx_operations = []
                except Exception as e:
                    logger.warning(f"  æ‰¹é‡åŒæ­¥TDXå¤±è´¥: {e}")
                    tdx_operations = []
        
        if tdx_operations:
            try:
                result = await collection.bulk_write(tdx_operations, ordered=False)
                tdx_update_count += result.modified_count + result.upserted_count
            except Exception as e:
                logger.warning(f"  æœ€åä¸€æ‰¹TDXåŒæ­¥å¤±è´¥: {e}")
        
        logger.info(f"âœ… å…±åŒæ­¥ {tdx_update_count} æ¡TDXæ•°æ®æºè®°å½•")
        
        # 5. éªŒè¯ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤5: éªŒè¯åŒæ­¥ç»“æœ...")
        
        # ç»Ÿè®¡å„æ•°æ®æºçš„è¡Œä¸šæ•°æ®
        for source in ['akshare', 'tdx']:
            total = await collection.count_documents({"source": source})
            with_industry = await collection.count_documents({
                "source": source,
                "industry": {"$ne": None, "$ne": "", "$exists": True}
            })
            logger.info(f"  {source.upper()}æ•°æ®æº:")
            logger.info(f"    è‚¡ç¥¨æ€»æ•°: {total}")
            logger.info(f"    æœ‰è¡Œä¸šæ•°æ®: {with_industry}")
            logger.info(f"    è¦†ç›–ç‡: {with_industry*100//total if total > 0 else 0}%")
        
        # ç»Ÿè®¡è¡Œä¸šåˆ†å¸ƒ
        pipeline = [
            {
                "$match": {
                    "source": {"$in": ["akshare", "tdx"]},
                    "industry": {"$ne": None, "$ne": "", "$exists": True}
                }
            },
            {
                "$group": {
                    "_id": "$industry",
                    "count": {"$sum": 1}
                }
            },
            {"$sort": {"count": -1}},
            {"$limit": 20}
        ]
        
        industries = []
        async for doc in collection.aggregate(pipeline):
            industries.append({
                "industry": doc.get("_id"),
                "count": doc.get("count", 0)
            })
        
        if industries:
            logger.info(f"\nğŸ“Š å‰20ä¸ªè¡Œä¸šåˆ†å¸ƒ:")
            for i, ind in enumerate(industries, 1):
                logger.info(f"  {i}. {ind['industry']}: {ind['count']}åªè‚¡ç¥¨")
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ è¡Œä¸šæ•°æ®åŒæ­¥å®Œæˆï¼")
        logger.info("=" * 80)
        
    except ImportError:
        logger.error("âŒ akshareåº“æœªå®‰è£…")
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥å¤±è´¥: {e}", exc_info=True)
    finally:
        client.close()


if __name__ == "__main__":
    asyncio.run(sync_industries_from_mapping())


