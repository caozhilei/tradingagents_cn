#!/usr/bin/env python3
"""
å°†å…¶ä»–æ•°æ®æºçš„è¡Œä¸šæ•°æ®åŒæ­¥åˆ°TDXæ•°æ®æº
ç”±äºTDXä¸»è¦ç”¨äºå®æ—¶è¡Œæƒ…ï¼Œä¸æä¾›è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œéœ€è¦ä»å…¶ä»–æ•°æ®æºè¡¥å……è¡Œä¸šæ•°æ®
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import UpdateOne
from app.core.config import settings
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


async def sync_industry_to_tdx():
    """å°†å…¶ä»–æ•°æ®æºçš„è¡Œä¸šæ•°æ®åŒæ­¥åˆ°TDXæ•°æ®æº"""
    logger.info("=" * 80)
    logger.info("ğŸš€ å¼€å§‹å°†è¡Œä¸šæ•°æ®åŒæ­¥åˆ°TDXæ•°æ®æº")
    logger.info("=" * 80)
    
    # è¿æ¥MongoDB
    logger.info("\nğŸ”Œ è¿æ¥MongoDB...")
    client = AsyncIOMotorClient(settings.MONGO_URI)
    db = client[settings.MONGO_DB]
    collection = db["stock_basic_info"]
    
    try:
        # 1. æŸ¥æ‰¾æœ‰è¡Œä¸šæ•°æ®çš„å…¶ä»–æ•°æ®æºï¼ˆakshare, tushare, baostockï¼‰
        logger.info("\nğŸ“‹ æ­¥éª¤1: æŸ¥æ‰¾æœ‰è¡Œä¸šæ•°æ®çš„å…¶ä»–æ•°æ®æº...")
        
        source_priority = ['akshare', 'tushare', 'baostock']
        industry_map = {}  # {code: industry}
        
        for source in source_priority:
            pipeline = [
                {
                    "$match": {
                        "source": source,
                        "industry": {"$ne": None, "$ne": "", "$exists": True}
                    }
                },
                {
                    "$project": {
                        "code": 1,
                        "symbol": 1,
                        "industry": 1
                    }
                }
            ]
            
            count = 0
            async for doc in collection.aggregate(pipeline):
                code = doc.get("code") or doc.get("symbol")
                if code:
                    code = str(code).zfill(6)
                    industry = doc.get("industry", "").strip()
                    if industry and code not in industry_map:
                        industry_map[code] = industry
                        count += 1
            
            logger.info(f"  ä» {source} è·å– {count} åªè‚¡ç¥¨çš„è¡Œä¸šæ•°æ®")
        
        logger.info(f"\nâœ… å…±è·å– {len(industry_map)} åªè‚¡ç¥¨çš„è¡Œä¸šæ•°æ®")
        
        if not industry_map:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¡Œä¸šæ•°æ®ï¼Œæ— æ³•åŒæ­¥")
            return
        
        # 2. æ£€æŸ¥TDXæ•°æ®æºçš„è‚¡ç¥¨æ•°æ®
        logger.info("\nğŸ“‹ æ­¥éª¤2: æ£€æŸ¥TDXæ•°æ®æºçš„è‚¡ç¥¨æ•°æ®...")
        
        tdx_stocks = await collection.find(
            {"source": "tdx"},
            {"code": 1, "symbol": 1}
        ).to_list(length=None)
        
        logger.info(f"  æ•°æ®åº“ä¸­æœ‰ {len(tdx_stocks)} åªTDXæ•°æ®æºçš„è‚¡ç¥¨")
        
        if len(tdx_stocks) == 0:
            logger.info("\nğŸ’¡ æ•°æ®åº“ä¸­æ²¡æœ‰TDXæ•°æ®æºçš„è‚¡ç¥¨ï¼Œå°†åˆ›å»ºTDXæ•°æ®æºè®°å½•...")
            
            # ä»å…¶ä»–æ•°æ®æºè·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œåˆ›å»ºTDXæ•°æ®æºè®°å½•
            logger.info("  ä»å…¶ä»–æ•°æ®æºè·å–è‚¡ç¥¨åˆ—è¡¨...")
            
            all_stocks = await collection.find(
                {"source": {"$in": source_priority}},
                {"code": 1, "symbol": 1, "name": 1}
            ).to_list(length=None)
            
            # å»é‡
            stock_dict = {}
            for doc in all_stocks:
                code = doc.get("code") or doc.get("symbol")
                if code:
                    code = str(code).zfill(6)
                    if code not in stock_dict:
                        stock_dict[code] = {
                            "code": code,
                            "symbol": code,
                            "name": doc.get("name", f"è‚¡ç¥¨{code}")
                        }
            
            logger.info(f"  å‡†å¤‡åˆ›å»º {len(stock_dict)} åªè‚¡ç¥¨çš„TDXæ•°æ®æºè®°å½•...")
            
            # æ‰¹é‡åˆ›å»ºTDXæ•°æ®æºè®°å½•
            operations = []
            created_count = 0
            
            for code, stock_info in stock_dict.items():
                industry = industry_map.get(code, "")
                
                operations.append(
                    UpdateOne(
                        {"code": code, "source": "tdx"},
                        {
                            "$set": {
                                "code": code,
                                "symbol": code,
                                "name": stock_info["name"],
                                "industry": industry,
                                "source": "tdx",
                                "updated_at": datetime.utcnow()
                            }
                        },
                        upsert=True
                    )
                )
                
                if industry:
                    created_count += 1
                
                # æ‰¹é‡æ‰§è¡Œ
                if len(operations) >= 100:
                    try:
                        await collection.bulk_write(operations, ordered=False)
                        logger.info(f"  å·²åˆ›å»º {len(operations)} æ¡TDXè®°å½•...")
                        operations = []
                    except Exception as e:
                        logger.warning(f"  æ‰¹é‡åˆ›å»ºå¤±è´¥: {e}")
                        operations = []
            
            # å¤„ç†å‰©ä½™çš„
            if operations:
                try:
                    await collection.bulk_write(operations, ordered=False)
                    logger.info(f"  å·²åˆ›å»ºæœ€å {len(operations)} æ¡TDXè®°å½•...")
                except Exception as e:
                    logger.warning(f"  æœ€åä¸€æ‰¹åˆ›å»ºå¤±è´¥: {e}")
            
            logger.info(f"âœ… å…±åˆ›å»º {len(stock_dict)} æ¡TDXæ•°æ®æºè®°å½•ï¼Œå…¶ä¸­ {created_count} æ¡åŒ…å«è¡Œä¸šæ•°æ®")
        
        else:
            # 3. æ›´æ–°ç°æœ‰TDXæ•°æ®æºçš„è¡Œä¸šæ•°æ®
            logger.info("\nğŸ“‹ æ­¥éª¤3: æ›´æ–°ç°æœ‰TDXæ•°æ®æºçš„è¡Œä¸šæ•°æ®...")
            
            operations = []
            update_count = 0
            
            for doc in tdx_stocks:
                code = doc.get("code") or doc.get("symbol")
                if code:
                    code = str(code).zfill(6)
                    industry = industry_map.get(code)
                    
                    if industry:
                        operations.append(
                            UpdateOne(
                                {"code": code, "source": "tdx"},
                                {
                                    "$set": {
                                        "industry": industry,
                                        "updated_at": datetime.utcnow()
                                    }
                                }
                            )
                        )
                        update_count += 1
                        
                        # æ‰¹é‡æ‰§è¡Œ
                        if len(operations) >= 100:
                            try:
                                result = await collection.bulk_write(operations, ordered=False)
                                logger.info(f"  å·²æ›´æ–° {result.modified_count} æ¡è®°å½•...")
                                operations = []
                            except Exception as e:
                                logger.warning(f"  æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
                                operations = []
            
            # å¤„ç†å‰©ä½™çš„
            if operations:
                try:
                    result = await collection.bulk_write(operations, ordered=False)
                    logger.info(f"  å·²æ›´æ–°æœ€å {result.modified_count} æ¡è®°å½•...")
                except Exception as e:
                    logger.warning(f"  æœ€åä¸€æ‰¹æ›´æ–°å¤±è´¥: {e}")
            
            logger.info(f"âœ… å…±æ›´æ–° {update_count} æ¡TDXæ•°æ®æºè®°å½•çš„è¡Œä¸šæ•°æ®")
        
        # 4. éªŒè¯ç»“æœ
        logger.info("\nğŸ“‹ æ­¥éª¤4: éªŒè¯åŒæ­¥ç»“æœ...")
        
        tdx_with_industry = await collection.count_documents({
            "source": "tdx",
            "industry": {"$ne": None, "$ne": "", "$exists": True}
        })
        
        tdx_total = await collection.count_documents({"source": "tdx"})
        
        logger.info(f"  TDXæ•°æ®æºè‚¡ç¥¨æ€»æ•°: {tdx_total}")
        logger.info(f"  æœ‰è¡Œä¸šæ•°æ®çš„è‚¡ç¥¨æ•°: {tdx_with_industry}")
        logger.info(f"  è¡Œä¸šæ•°æ®è¦†ç›–ç‡: {tdx_with_industry*100//tdx_total if tdx_total > 0 else 0}%")
        
        # 5. ç»Ÿè®¡è¡Œä¸šåˆ†å¸ƒ
        pipeline = [
            {
                "$match": {
                    "source": "tdx",
                    "industry": {"$ne": None, "$ne": "", "$exists": True}
                }
            },
            {
                "$group": {
                    "_id": "$industry",
                    "count": {"$sum": 1}
                }
            },
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]
        
        industries = []
        async for doc in collection.aggregate(pipeline):
            industries.append({
                "industry": doc.get("_id"),
                "count": doc.get("count", 0)
            })
        
        if industries:
            logger.info(f"\nğŸ“Š TDXæ•°æ®æºå‰10ä¸ªè¡Œä¸š:")
            for i, ind in enumerate(industries, 1):
                logger.info(f"  {i}. {ind['industry']}: {ind['count']}åªè‚¡ç¥¨")
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ è¡Œä¸šæ•°æ®åŒæ­¥å®Œæˆï¼")
        logger.info("=" * 80)
        
    finally:
        client.close()


if __name__ == "__main__":
    asyncio.run(sync_industry_to_tdx())

