#!/usr/bin/env python3
"""
ä»AKShareæ‰¹é‡åŒæ­¥è¡Œä¸šæ•°æ®
ä½¿ç”¨è¡Œä¸šæ¿å—æ¥å£æ‰¹é‡è·å–è‚¡ç¥¨è¡Œä¸šä¿¡æ¯ï¼Œæ¯”é€ä¸ªè‚¡ç¥¨æŸ¥è¯¢æ›´é«˜æ•ˆ
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import UpdateOne
from app.core.config import settings
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


async def sync_industries_from_akshare():
    """ä»AKShareæ‰¹é‡åŒæ­¥è¡Œä¸šæ•°æ®"""
    try:
        import akshare as ak
        
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹ä»AKShareæ‰¹é‡åŒæ­¥è¡Œä¸šæ•°æ®")
        logger.info("=" * 80)
        
        # 1. è·å–æ‰€æœ‰è¡Œä¸šæ¿å—åˆ—è¡¨
        logger.info("\nğŸ“‹ æ­¥éª¤1: è·å–è¡Œä¸šæ¿å—åˆ—è¡¨...")
        
        def fetch_industries():
            return ak.stock_board_industry_name_em()
        
        industries_df = await asyncio.to_thread(fetch_industries)
        
        if industries_df is None or industries_df.empty:
            logger.error("âŒ æœªè·å–åˆ°è¡Œä¸šæ¿å—åˆ—è¡¨")
            return
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(industries_df)} ä¸ªè¡Œä¸šæ¿å—")
        
        # 2. è¿æ¥MongoDB
        logger.info("\nğŸ”Œ æ­¥éª¤2: è¿æ¥MongoDB...")
        client = AsyncIOMotorClient(settings.MONGO_URI)
        db = client[settings.MONGO_DB]
        collection = db["stock_basic_info"]
        
        # 3. ç»Ÿè®¡ä¿¡æ¯
        total_updated = 0
        total_processed = 0
        industry_stock_map: Dict[str, List[str]] = {}
        
        # 4. éå†æ¯ä¸ªè¡Œä¸šæ¿å—ï¼Œè·å–è¯¥è¡Œä¸šä¸‹çš„è‚¡ç¥¨
        logger.info("\nğŸ“Š æ­¥éª¤3: æ‰¹é‡è·å–å„è¡Œä¸šçš„è‚¡ç¥¨åˆ—è¡¨...")
        logger.info(f"   å…± {len(industries_df)} ä¸ªè¡Œä¸šéœ€è¦å¤„ç†\n")
        
        for idx, row in industries_df.iterrows():
            industry_name = str(row.get('æ¿å—åç§°', '')).strip()
            if not industry_name:
                continue
            
            try:
                # è·å–è¯¥è¡Œä¸šçš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
                stocks_df = None
                max_retries = 3
                for retry in range(max_retries):
                    try:
                        def fetch_stocks():
                            return ak.stock_board_industry_cons_em(symbol=industry_name)
                        
                        stocks_df = await asyncio.to_thread(fetch_stocks)
                        break  # æˆåŠŸè·å–ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    except Exception as e:
                        if retry < max_retries - 1:
                            wait_time = (retry + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š2s, 4s, 6s
                            logger.debug(f"    é‡è¯• {retry + 1}/{max_retries}ï¼Œç­‰å¾… {wait_time}ç§’...")
                            await asyncio.sleep(wait_time)
                        else:
                            raise e  # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                
                if stocks_df is None or stocks_df.empty:
                    logger.debug(f"  âš ï¸  è¡Œä¸š {industry_name} æ²¡æœ‰è‚¡ç¥¨æ•°æ®")
                    continue
                
                # æå–è‚¡ç¥¨ä»£ç 
                stock_codes = []
                for _, stock_row in stocks_df.iterrows():
                    code = str(stock_row.get('ä»£ç ', '')).strip()
                    if code:
                        # ç¡®ä¿ä»£ç æ˜¯6ä½
                        code = code.zfill(6)
                        stock_codes.append(code)
                        industry_stock_map[code] = industry_name
                
                total_processed += len(stock_codes)
                logger.info(f"  âœ… [{idx+1}/{len(industries_df)}] {industry_name}: {len(stock_codes)} åªè‚¡ç¥¨")
                
                # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.warning(f"  âš ï¸  å¤„ç†è¡Œä¸š {industry_name} å¤±è´¥: {e}")
                continue
        
        logger.info(f"\nâœ… å…±è·å– {total_processed} åªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯")
        
        # 5. æ‰¹é‡æ›´æ–°æ•°æ®åº“
        logger.info("\nğŸ’¾ æ­¥éª¤4: æ‰¹é‡æ›´æ–°æ•°æ®åº“...")
        
        update_count = 0
        batch_size = 100
        batch = []
        
        for code, industry in industry_stock_map.items():
            batch.append(
                UpdateOne(
                    {"code": code, "source": "akshare"},
                    {"$set": {"industry": industry, "updated_at": datetime.utcnow()}},
                    upsert=False
                )
            )
            
            # æ‰¹é‡æ‰§è¡Œ
            if len(batch) >= batch_size:
                try:
                    result = await collection.bulk_write(batch, ordered=False)
                    update_count += result.modified_count
                    logger.info(f"  å·²æ›´æ–° {update_count} åªè‚¡ç¥¨...")
                except Exception as e:
                    logger.warning(f"  æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
                finally:
                    batch = []
        
        # å¤„ç†å‰©ä½™çš„
        if batch:
            try:
                result = await collection.bulk_write(batch, ordered=False)
                update_count += result.modified_count
            except Exception as e:
                logger.warning(f"  æœ€åä¸€æ‰¹æ›´æ–°å¤±è´¥: {e}")
        
        logger.info(f"âœ… æ‰¹é‡æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {update_count} åªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯")
        
        # 6. éªŒè¯ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤5: éªŒè¯æ›´æ–°ç»“æœ...")
        updated_count = await collection.count_documents({
            "source": "akshare",
            "industry": {"$ne": None, "$ne": "", "$exists": True}
        })
        logger.info(f"âœ… æ•°æ®åº“ä¸­AKShareæ•°æ®æºæœ‰è¡Œä¸šæ•°æ®çš„è‚¡ç¥¨: {updated_count} åª")
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ æ‰¹é‡åŒæ­¥å®Œæˆï¼")
        logger.info("=" * 80)
        
        client.close()
        
    except ImportError:
        logger.error("âŒ akshareåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install akshare")
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡åŒæ­¥å¤±è´¥: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(sync_industries_from_akshare())

