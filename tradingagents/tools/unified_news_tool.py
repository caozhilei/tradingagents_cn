#!/usr/bin/env python3
"""
ç»Ÿä¸€æ–°é—»åˆ†æå·¥å…·
æ•´åˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ç­‰ä¸åŒå¸‚åœºçš„æ–°é—»è·å–é€»è¾‘åˆ°ä¸€ä¸ªå·¥å…·å‡½æ•°ä¸­
è®©å¤§æ¨¡å‹åªéœ€è¦è°ƒç”¨ä¸€ä¸ªå·¥å…·å°±èƒ½è·å–æ‰€æœ‰ç±»å‹è‚¡ç¥¨çš„æ–°é—»æ•°æ®
"""

import logging
from datetime import datetime
import re
import os

logger = logging.getLogger(__name__)

class UnifiedNewsAnalyzer:
    """ç»Ÿä¸€æ–°é—»åˆ†æå™¨ï¼Œæ•´åˆæ‰€æœ‰æ–°é—»è·å–é€»è¾‘"""
    
    def __init__(self, toolkit):
        """åˆå§‹åŒ–ç»Ÿä¸€æ–°é—»åˆ†æå™¨
        
        Args:
            toolkit: åŒ…å«å„ç§æ–°é—»è·å–å·¥å…·çš„å·¥å…·åŒ…
        """
        self.toolkit = toolkit
        
    def get_stock_news_unified(self, stock_code: str, max_news: int = 10, model_info: str = "", current_date: str = None) -> str:
        """
        ç»Ÿä¸€æ–°é—»è·å–æ¥å£
        æ ¹æ®è‚¡ç¥¨ä»£ç è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹å¹¶è·å–ç›¸åº”æ–°é—»
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            max_news: æœ€å¤§æ–°é—»æ•°é‡
            model_info: å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯ï¼Œç”¨äºç‰¹æ®Šå¤„ç†
            current_date: åˆ†ææ—¶é—´ç‚¹ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼Œåªè·å–è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æ–°é—»
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹
        """
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å¼€å§‹è·å– {stock_code} çš„æ–°é—»ï¼Œæ¨¡å‹: {model_info}")
        if current_date:
            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“… åˆ†ææ—¶é—´ç‚¹: {current_date}ï¼ˆåªè·å–è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æ–°é—»ï¼‰")
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ¤– å½“å‰æ¨¡å‹ä¿¡æ¯: {model_info}")
        
        # è¯†åˆ«è‚¡ç¥¨ç±»å‹
        stock_type = self._identify_stock_type(stock_code)
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è‚¡ç¥¨ç±»å‹: {stock_type}")
        
        # æ ¹æ®è‚¡ç¥¨ç±»å‹è°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
        if stock_type == "Aè‚¡":
            result = self._get_a_share_news(stock_code, max_news, model_info, current_date)
        elif stock_type == "æ¸¯è‚¡":
            result = self._get_hk_share_news(stock_code, max_news, model_info, current_date)
        elif stock_type == "æ•°å­—è´§å¸":
            result = self._get_crypto_news(stock_code, max_news, model_info, current_date)
        elif stock_type == "ç¾è‚¡":
            result = self._get_us_share_news(stock_code, max_news, model_info, current_date)
        else:
            # é»˜è®¤ä½¿ç”¨Aè‚¡é€»è¾‘
            result = self._get_a_share_news(stock_code, max_news, model_info, current_date)
        
        # ğŸ” æ·»åŠ è¯¦ç»†çš„ç»“æœè°ƒè¯•æ—¥å¿—
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“Š æ–°é—»è·å–å®Œæˆï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“‹ è¿”å›ç»“æœé¢„è§ˆ (å‰1000å­—ç¬¦): {result[:1000]}")
        
        # å¦‚æœç»“æœä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè®°å½•è­¦å‘Š
        if not result or len(result.strip()) < 50:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ è¿”å›ç»“æœå¼‚å¸¸çŸ­æˆ–ä¸ºç©ºï¼")
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“ å®Œæ•´ç»“æœå†…å®¹: '{result}'")
        
        return result
    
    def _identify_stock_type(self, stock_code: str) -> str:
        """è¯†åˆ«è‚¡ç¥¨ç±»å‹"""
        stock_code = stock_code.upper().strip()
        
        # Aè‚¡åˆ¤æ–­
        if re.match(r'^(00|30|60|68)\d{4}$', stock_code):
            return "Aè‚¡"
        elif re.match(r'^(SZ|SH)\d{6}$', stock_code):
            return "Aè‚¡"
        
        # æ¸¯è‚¡åˆ¤æ–­
        elif re.match(r'^\d{4,5}\.HK$', stock_code):
            return "æ¸¯è‚¡"
        elif re.match(r'^\d{4,5}$', stock_code) and len(stock_code) <= 5:
            return "æ¸¯è‚¡"
        
        # æ•°å­—è´§å¸åˆ¤æ–­ï¼ˆä¼˜å…ˆäºç¾è‚¡ï¼Œå› ä¸ºBTCç­‰æ•°å­—è´§å¸ä»£ç ä¹ŸåŒ¹é…ç¾è‚¡æ ¼å¼ï¼‰
        crypto_codes = {
            'BTC', 'ETH', 'DOGE', 'USDT', 'BNB', 'ADA', 'SOL', 'DOT', 'AVAX', 'LINK',
            'UNI', 'ALGO', 'VET', 'ICP', 'FIL', 'TRX', 'ETC', 'XLM', 'THETA', 'HBAR',
            'NEAR', 'FLOW', 'MANA', 'SAND', 'AXS', 'GALA', 'ENJ', 'BAT', 'CHZ', 'GAL',
            'YGG', 'APE', 'LRC', 'ENS', 'LOOKS', 'BEAN', 'PEPE', 'SHIB', 'FLOKI'
        }
        if stock_code in crypto_codes:
            return "æ•°å­—è´§å¸"
        
        # ç¾è‚¡åˆ¤æ–­
        elif re.match(r'^[A-Z]{1,5}$', stock_code):
            return "ç¾è‚¡"
        elif '.' in stock_code and not stock_code.endswith('.HK'):
            return "ç¾è‚¡"
        
        # é»˜è®¤æŒ‰Aè‚¡å¤„ç†
        else:
            return "Aè‚¡"

    def _get_news_from_database(self, stock_code: str, max_news: int = 10, current_date: str = None) -> str:
        """
        ä»æ•°æ®åº“è·å–æ–°é—»

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            max_news: æœ€å¤§æ–°é—»æ•°é‡
            current_date: åˆ†ææ—¶é—´ç‚¹ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼Œåªè·å–è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æ–°é—»

        Returns:
            str: æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ–°é—»åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            from tradingagents.dataflows.cache.app_adapter import get_mongodb_client
            from datetime import timedelta

            # ğŸ”§ ç¡®ä¿ max_news æ˜¯æ•´æ•°ï¼ˆé˜²æ­¢ä¼ å…¥æµ®ç‚¹æ•°ï¼‰
            max_news = int(max_news)

            client = get_mongodb_client()
            if not client:
                logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] æ— æ³•è¿æ¥åˆ°MongoDB")
                return ""

            db = client.get_database('tradingagents')
            collection = db.stock_news

            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆå»é™¤åç¼€ï¼‰
            clean_code = stock_code.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                                   .replace('.XSHE', '').replace('.XSHG', '').replace('.HK', '')

            # ğŸ”¥ æ ¹æ® current_date è®¾ç½®æ—¶é—´è¿‡æ»¤æ¡ä»¶
            time_filter = {}
            if current_date:
                try:
                    # å°†å­—ç¬¦ä¸²æ—¥æœŸè½¬æ¢ä¸º datetime å¯¹è±¡ï¼ˆä½œä¸ºæˆªæ­¢æ—¶é—´ï¼‰
                    from datetime import datetime as dt
                    analysis_date = dt.strptime(current_date, "%Y-%m-%d")
                    # è®¾ç½®æˆªæ­¢æ—¶é—´ä¸ºåˆ†ææ—¥æœŸçš„23:59:59
                    analysis_date_end = dt.combine(analysis_date.date(), dt.max.time())
                    time_filter = {'$lte': analysis_date_end}
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“… ä½¿ç”¨åˆ†ææ—¶é—´ç‚¹è¿‡æ»¤: åªè·å– {current_date} ä¹‹å‰çš„æ–°é—»")
                except Exception as e:
                    logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ è§£æ current_date å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ—¶é—´èŒƒå›´")
                    # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çš„30å¤©èŒƒå›´
                    thirty_days_ago = datetime.now() - timedelta(days=30)
                    time_filter = {'$gte': thirty_days_ago}
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®š current_dateï¼Œä½¿ç”¨é»˜è®¤çš„30å¤©èŒƒå›´
                thirty_days_ago = datetime.now() - timedelta(days=30)
                time_filter = {'$gte': thirty_days_ago}
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“… æœªæŒ‡å®šåˆ†ææ—¶é—´ç‚¹ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘30å¤©ï¼‰")

            # å°è¯•å¤šç§æŸ¥è¯¢æ–¹å¼ï¼ˆä½¿ç”¨ symbol å­—æ®µï¼‰
            query_list = [
                {'symbol': clean_code, 'publish_time': time_filter},
                {'symbol': stock_code, 'publish_time': time_filter},
                {'symbols': clean_code, 'publish_time': time_filter},
                # å¦‚æœæŒ‡å®šäº†æ—¶é—´ç‚¹ä½†è¯¥æ—¶é—´ç‚¹ä¹‹å‰æ²¡æœ‰æ–°é—»ï¼Œåˆ™æŸ¥è¯¢æ‰€æœ‰æ–°é—»ï¼ˆä¸é™æ—¶é—´ï¼‰
                {'symbol': clean_code},
                {'symbols': clean_code},
            ]

            news_items = []
            for query in query_list:
                cursor = collection.find(query).sort('publish_time', -1).limit(max_news)
                news_items = list(cursor)
                if news_items:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“Š ä½¿ç”¨æŸ¥è¯¢ {query} æ‰¾åˆ° {len(news_items)} æ¡æ–°é—»")
                    break

            if not news_items:
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ° {stock_code} çš„æ–°é—»")
                return ""

            # æ ¼å¼åŒ–æ–°é—»
            report = f"# {stock_code} æœ€æ–°æ–°é—» (æ•°æ®åº“ç¼“å­˜)\n\n"
            report += f"ğŸ“… æŸ¥è¯¢æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            if current_date:
                report += f"ğŸ“… åˆ†ææ—¶é—´ç‚¹: {current_date}ï¼ˆä»…æ˜¾ç¤ºè¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æ–°é—»ï¼‰\n"
            report += f"ğŸ“Š æ–°é—»æ•°é‡: {len(news_items)} æ¡\n\n"

            for i, news in enumerate(news_items, 1):
                title = news.get('title', 'æ— æ ‡é¢˜')
                content = news.get('content', '') or news.get('summary', '')
                source = news.get('source', 'æœªçŸ¥æ¥æº')
                publish_time = news.get('publish_time', datetime.now())
                sentiment = news.get('sentiment', 'neutral')

                # æƒ…ç»ªå›¾æ ‡
                sentiment_icon = {
                    'positive': 'ğŸ“ˆ',
                    'negative': 'ğŸ“‰',
                    'neutral': 'â–'
                }.get(sentiment, 'â–')

                report += f"## {i}. {sentiment_icon} {title}\n\n"
                report += f"**æ¥æº**: {source} | **æ—¶é—´**: {publish_time.strftime('%Y-%m-%d %H:%M') if isinstance(publish_time, datetime) else publish_time}\n"
                report += f"**æƒ…ç»ª**: {sentiment}\n\n"

                if content:
                    # é™åˆ¶å†…å®¹é•¿åº¦
                    content_preview = content[:500] + '...' if len(content) > 500 else content
                    report += f"{content_preview}\n\n"

                report += "---\n\n"

            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… æˆåŠŸä»æ•°æ®åº“è·å–å¹¶æ ¼å¼åŒ– {len(news_items)} æ¡æ–°é—»")
            return report

        except Exception as e:
            logger.error(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ä»æ•°æ®åº“è·å–æ–°é—»å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return ""

    def _sync_news_from_akshare(self, stock_code: str, max_news: int = 10) -> bool:
        """
        ä»AKShareåŒæ­¥æ–°é—»åˆ°æ•°æ®åº“ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰
        ä½¿ç”¨åŒæ­¥çš„æ•°æ®åº“å®¢æˆ·ç«¯å’Œæ–°çº¿ç¨‹ä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œé¿å…äº‹ä»¶å¾ªç¯å†²çª

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            max_news: æœ€å¤§æ–°é—»æ•°é‡

        Returns:
            bool: æ˜¯å¦åŒæ­¥æˆåŠŸ
        """
        try:
            import asyncio
            import concurrent.futures

            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆå»é™¤åç¼€ï¼‰
            clean_code = stock_code.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                                   .replace('.XSHE', '').replace('.XSHG', '').replace('.HK', '')

            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ”„ å¼€å§‹åŒæ­¥ {clean_code} çš„æ–°é—»...")

            # ğŸ”¥ åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œï¼Œä½¿ç”¨åŒæ­¥æ•°æ®åº“å®¢æˆ·ç«¯
            def run_sync_in_new_thread():
                """åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯å¹¶è¿è¡ŒåŒæ­¥ä»»åŠ¡"""
                # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)

                try:
                    # å®šä¹‰å¼‚æ­¥è·å–æ–°é—»ä»»åŠ¡
                    async def get_news_task():
                        try:
                            # åŠ¨æ€å¯¼å…¥ AKShare providerï¼ˆæ­£ç¡®çš„å¯¼å…¥è·¯å¾„ï¼‰
                            from tradingagents.dataflows.providers.china.akshare import AKShareProvider

                            # åˆ›å»º provider å®ä¾‹
                            provider = AKShareProvider()

                            # è°ƒç”¨ provider è·å–æ–°é—»
                            news_data = await provider.get_stock_news(
                                symbol=clean_code,
                                limit=max_news
                            )

                            return news_data

                        except Exception as e:
                            logger.error(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âŒ è·å–æ–°é—»å¤±è´¥: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            return None

                    # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è·å–æ–°é—»
                    news_data = new_loop.run_until_complete(get_news_task())

                    if not news_data:
                        logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ æœªè·å–åˆ°æ–°é—»æ•°æ®")
                        return False

                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“¥ è·å–åˆ° {len(news_data)} æ¡æ–°é—»")

                    # ğŸ”¥ ä½¿ç”¨åŒæ­¥æ–¹æ³•ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä¸ä¾èµ–äº‹ä»¶å¾ªç¯ï¼‰
                    from app.services.news_data_service import NewsDataService

                    news_service = NewsDataService()
                    saved_count = news_service.save_news_data_sync(
                        news_data=news_data,
                        data_source="akshare",
                        market="CN"
                    )

                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… åŒæ­¥æˆåŠŸ: {saved_count} æ¡æ–°é—»")
                    return saved_count > 0

                finally:
                    # æ¸…ç†äº‹ä»¶å¾ªç¯
                    new_loop.close()

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡ŒåŒæ­¥ä»»åŠ¡ï¼Œé¿å…äº‹ä»¶å¾ªç¯å†²çª")
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(run_sync_in_new_thread)
                result = future.result(timeout=30)  # 30ç§’è¶…æ—¶
                return result

        except concurrent.futures.TimeoutError:
            logger.error(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âŒ åŒæ­¥æ–°é—»è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
            return False
        except Exception as e:
            logger.error(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âŒ åŒæ­¥æ–°é—»å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _get_a_share_news(self, stock_code: str, max_news: int, model_info: str = "", current_date: str = None) -> str:
        """è·å–Aè‚¡æ–°é—»"""
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è·å–Aè‚¡ {stock_code} æ–°é—»")

        # è·å–å½“å‰æ—¥æœŸï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ†ææ—¶é—´ç‚¹ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸï¼‰
        if current_date:
            curr_date = current_date
        else:
            curr_date = datetime.now().strftime("%Y-%m-%d")

        # ä¼˜å…ˆçº§0: ä»æ•°æ®åº“è·å–æ–°é—»ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        try:
            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ” ä¼˜å…ˆä»æ•°æ®åº“è·å– {stock_code} çš„æ–°é—»...")
            db_news = self._get_news_from_database(stock_code, max_news, current_date)
            if db_news:
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… æ•°æ®åº“æ–°é—»è·å–æˆåŠŸ: {len(db_news)} å­—ç¬¦")
                return self._format_news_result(db_news, "æ•°æ®åº“ç¼“å­˜", model_info)
            else:
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰ {stock_code} çš„æ–°é—»ï¼Œå°è¯•åŒæ­¥...")

                # ğŸ”¥ æ•°æ®åº“æ²¡æœ‰æ•°æ®æ—¶ï¼Œè°ƒç”¨åŒæ­¥æœåŠ¡åŒæ­¥æ–°é—»
                try:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“¡ è°ƒç”¨åŒæ­¥æœåŠ¡åŒæ­¥ {stock_code} çš„æ–°é—»...")
                    synced_news = self._sync_news_from_akshare(stock_code, max_news)

                    if synced_news:
                        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… åŒæ­¥æˆåŠŸï¼Œé‡æ–°ä»æ•°æ®åº“è·å–...")
                        # é‡æ–°ä»æ•°æ®åº“è·å–
                        db_news = self._get_news_from_database(stock_code, max_news)
                        if db_news:
                            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… åŒæ­¥åæ•°æ®åº“æ–°é—»è·å–æˆåŠŸ: {len(db_news)} å­—ç¬¦")
                            return self._format_news_result(db_news, "æ•°æ®åº“ç¼“å­˜(æ–°åŒæ­¥)", model_info)
                    else:
                        logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ åŒæ­¥æœåŠ¡æœªè¿”å›æ–°é—»æ•°æ®")

                except Exception as sync_error:
                    logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ åŒæ­¥æœåŠ¡è°ƒç”¨å¤±è´¥: {sync_error}")

                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ åŒæ­¥åä»æ— æ•°æ®ï¼Œå°è¯•å…¶ä»–æ•°æ®æº...")
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] æ•°æ®åº“æ–°é—»è·å–å¤±è´¥: {e}")

        # ä¼˜å…ˆçº§1: ä¸œæ–¹è´¢å¯Œå®æ—¶æ–°é—»
        try:
            if hasattr(self.toolkit, 'get_realtime_stock_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•ä¸œæ–¹è´¢å¯Œå®æ—¶æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_realtime_stock_news.invoke({"ticker": stock_code, "curr_date": curr_date})
                
                # ğŸ” è¯¦ç»†è®°å½•ä¸œæ–¹è´¢å¯Œè¿”å›çš„å†…å®¹
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“Š ä¸œæ–¹è´¢å¯Œè¿”å›å†…å®¹é•¿åº¦: {len(result) if result else 0} å­—ç¬¦")
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“‹ ä¸œæ–¹è´¢å¯Œè¿”å›å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦): {result[:500] if result else 'None'}")
                
                if result and len(result.strip()) > 100:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… ä¸œæ–¹è´¢å¯Œæ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "ä¸œæ–¹è´¢å¯Œå®æ—¶æ–°é—»", model_info)
                else:
                    logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ ä¸œæ–¹è´¢å¯Œæ–°é—»å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ä¸œæ–¹è´¢å¯Œæ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: Googleæ–°é—»ï¼ˆä¸­æ–‡æœç´¢ï¼‰
        try:
            if hasattr(self.toolkit, 'get_google_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•Googleæ–°é—»...")
                query = f"{stock_code} è‚¡ç¥¨ æ–°é—» è´¢æŠ¥ ä¸šç»©"
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_google_news.invoke({"query": query, "curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleæ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "Googleæ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleæ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: OpenAIå…¨çƒæ–°é—»
        try:
            if hasattr(self.toolkit, 'get_global_news_openai'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•OpenAIå…¨çƒæ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_global_news_openai.invoke({"curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… OpenAIæ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "OpenAIå…¨çƒæ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] OpenAIæ–°é—»è·å–å¤±è´¥: {e}")
        
        return "âŒ æ— æ³•è·å–Aè‚¡æ–°é—»æ•°æ®ï¼Œæ‰€æœ‰æ–°é—»æºå‡ä¸å¯ç”¨"
    
    def _get_hk_share_news(self, stock_code: str, max_news: int, model_info: str = "", current_date: str = None) -> str:
        """è·å–æ¸¯è‚¡æ–°é—»"""
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è·å–æ¸¯è‚¡ {stock_code} æ–°é—»")
        
        # è·å–å½“å‰æ—¥æœŸï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ†ææ—¶é—´ç‚¹ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸï¼‰
        if current_date:
            curr_date = current_date
        else:
            curr_date = datetime.now().strftime("%Y-%m-%d")
        
        # ä¼˜å…ˆçº§1: Googleæ–°é—»ï¼ˆæ¸¯è‚¡æœç´¢ï¼‰
        try:
            if hasattr(self.toolkit, 'get_google_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•Googleæ¸¯è‚¡æ–°é—»...")
                query = f"{stock_code} æ¸¯è‚¡ é¦™æ¸¯è‚¡ç¥¨ æ–°é—»"
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_google_news.invoke({"query": query, "curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleæ¸¯è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "Googleæ¸¯è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleæ¸¯è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: OpenAIå…¨çƒæ–°é—»
        try:
            if hasattr(self.toolkit, 'get_global_news_openai'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•OpenAIæ¸¯è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_global_news_openai.invoke({"curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… OpenAIæ¸¯è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "OpenAIæ¸¯è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] OpenAIæ¸¯è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: å®æ—¶æ–°é—»ï¼ˆå¦‚æœæ”¯æŒæ¸¯è‚¡ï¼‰
        try:
            if hasattr(self.toolkit, 'get_realtime_stock_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•å®æ—¶æ¸¯è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_realtime_stock_news.invoke({"ticker": stock_code, "curr_date": curr_date})
                if result and len(result.strip()) > 100:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… å®æ—¶æ¸¯è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "å®æ—¶æ¸¯è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å®æ—¶æ¸¯è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        return "âŒ æ— æ³•è·å–æ¸¯è‚¡æ–°é—»æ•°æ®ï¼Œæ‰€æœ‰æ–°é—»æºå‡ä¸å¯ç”¨"
    
    def _get_crypto_news(self, stock_code: str, max_news: int, model_info: str = "", current_date: str = None) -> str:
        """è·å–æ•°å­—è´§å¸æ–°é—»ï¼ˆå¤šæºèšåˆï¼‰"""
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è·å–æ•°å­—è´§å¸ {stock_code} æ–°é—»ï¼ˆå¤šæºèšåˆï¼‰")
        
        # è·å–å½“å‰æ—¥æœŸï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ†ææ—¶é—´ç‚¹ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸï¼‰
        if current_date:
            curr_date = current_date
        else:
            curr_date = datetime.now().strftime("%Y-%m-%d")
        
        # æ•°å­—è´§å¸åç§°æ˜ å°„ï¼ˆä¸­è‹±æ–‡ï¼‰
        crypto_names_en = {
            'BTC': 'bitcoin',
            'ETH': 'ethereum',
            'DOGE': 'dogecoin',
            'USDT': 'tether',
            'BNB': 'binance coin',
            'ADA': 'cardano',
            'SOL': 'solana',
            'DOT': 'polkadot',
            'AVAX': 'avalanche',
            'LINK': 'chainlink',
            'UNI': 'uniswap',
            'ALGO': 'algorand',
            'VET': 'vechain',
            'ICP': 'internet computer',
            'FIL': 'filecoin',
            'TRX': 'tron',
            'ETC': 'ethereum classic',
            'XLM': 'stellar',
            'THETA': 'theta',
            'HBAR': 'hedera',
            'NEAR': 'near protocol',
            'FLOW': 'flow',
            'MANA': 'decentraland',
            'SAND': 'sandbox',
            'AXS': 'axie infinity',
            'GALA': 'gala',
            'ENJ': 'enjin',
            'BAT': 'basic attention token',
            'CHZ': 'chiliz',
            'GAL': 'galxe',
            'YGG': 'yield guild games',
            'APE': 'apecoin',
            'LRC': 'loopring',
            'ENS': 'ethereum name service',
            'LOOKS': 'looksrare',
            'BEAN': 'bean',
            'PEPE': 'pepe',
            'SHIB': 'shiba inu',
            'FLOKI': 'floki'
        }
        
        crypto_names_cn = {
            'BTC': 'æ¯”ç‰¹å¸',
            'ETH': 'ä»¥å¤ªåŠ',
            'DOGE': 'ç‹—ç‹—å¸',
            'USDT': 'æ³°è¾¾å¸',
            'BNB': 'å¸å®‰å¸',
            'ADA': 'è‰¾è¾¾å¸',
            'SOL': 'ç´¢æ‹‰çº³',
            'DOT': 'æ³¢å¡',
            'AVAX': 'é›ªå´©',
            'LINK': 'Chainlink'
        }
        
        crypto_code = stock_code.upper()
        crypto_name_en = crypto_names_en.get(crypto_code, crypto_code.lower())
        crypto_name_cn = crypto_names_cn.get(crypto_code, crypto_code)
        
        # ========== ä¼˜å…ˆçº§1: Google News ==========
        try:
            if hasattr(self.toolkit, 'get_google_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ¥‡ ä¼˜å…ˆçº§1: å°è¯•Googleæ•°å­—è´§å¸æ–°é—»...")
                # æ„å»ºæœç´¢æŸ¥è¯¢ï¼ˆä¸­è‹±æ–‡æ··åˆï¼Œæé«˜æœç´¢è¦†ç›–ç‡ï¼‰
                query = f"{crypto_code} {crypto_name_en} cryptocurrency news"
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleæœç´¢æŸ¥è¯¢: {query}")
                
                result = self.toolkit.get_google_news.invoke({
                    "query": query,
                    "curr_date": curr_date,
                    "look_back_days": 7  # å›æº¯7å¤©
                })
                
                if result and len(result.strip()) > 100:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleæ•°å­—è´§å¸æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, f"Googleæ•°å­—è´§å¸æ–°é—»({crypto_name_cn})", model_info)
                else:
                    logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ Googleæ•°å­—è´§å¸æ–°é—»å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º: {len(result) if result else 0} å­—ç¬¦")
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleæ•°å­—è´§å¸æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ========== ä¼˜å…ˆçº§2: OpenAI å…¨çƒæ–°é—» ==========
        try:
            if hasattr(self.toolkit, 'get_global_news_openai'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ¥ˆ ä¼˜å…ˆçº§2: å°è¯•OpenAIå…¨çƒæ–°é—»...")
                result = self.toolkit.get_global_news_openai.invoke({"curr_date": curr_date})
                
                if result and len(result.strip()) > 100:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—è´§å¸ç›¸å…³å†…å®¹
                    crypto_keywords = [crypto_code, crypto_name_en, 'cryptocurrency', 'bitcoin', 'ethereum', 'crypto']
                    if any(keyword.lower() in result.lower() for keyword in crypto_keywords):
                        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… OpenAIå…¨çƒæ–°é—»åŒ…å«æ•°å­—è´§å¸å†…å®¹: {len(result)} å­—ç¬¦")
                        return self._format_news_result(result, f"OpenAIå…¨çƒæ–°é—»({crypto_name_cn})", model_info)
                    else:
                        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ OpenAIå…¨çƒæ–°é—»æœªåŒ…å«æ•°å­—è´§å¸ç›¸å…³å†…å®¹")
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] OpenAIå…¨çƒæ–°é—»è·å–å¤±è´¥: {e}")
        
        # ========== ä¼˜å…ˆçº§3: NewsAPIï¼ˆå¦‚æœé…ç½®äº†ï¼‰ ==========
        try:
            newsapi_key = os.getenv('NEWSAPI_KEY')
            if newsapi_key:
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ¥‰ ä¼˜å…ˆçº§3: å°è¯•NewsAPIæ•°å­—è´§å¸æ–°é—»...")
                
                import requests
                from datetime import timedelta
                from zoneinfo import ZoneInfo
                from tradingagents.utils.timezone_utils import get_timezone_name
                
                # æ„å»ºæœç´¢æŸ¥è¯¢
                query = f"{crypto_code} OR {crypto_name_en} OR cryptocurrency"
                
                # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆå›æº¯7å¤©ï¼‰
                end_time = datetime.now(ZoneInfo(get_timezone_name()))
                start_time = end_time - timedelta(days=7)
                
                url = "https://newsapi.org/v2/everything"
                params = {
                    'q': query,
                    'language': 'en',
                    'sortBy': 'publishedAt',
                    'from': start_time.isoformat(),
                    'to': end_time.isoformat(),
                    'pageSize': min(max_news, 20),  # NewsAPIå…è´¹ç‰ˆé™åˆ¶
                    'apiKey': newsapi_key
                }
                
                headers = {
                    'User-Agent': 'TradingAgents-CN/1.0'
                }
                
                response = requests.get(url, params=params, headers=headers, timeout=10)
                response.raise_for_status()
                
                data = response.json()
                articles = data.get('articles', [])
                
                if articles:
                    # æ ¼å¼åŒ–NewsAPIè¿”å›çš„æ–°é—»
                    news_str = f"## {crypto_name_cn} ({crypto_code}) NewsAPI æ–°é—»\n\n"
                    for i, article in enumerate(articles[:max_news], 1):
                        title = article.get('title', 'æ— æ ‡é¢˜')
                        description = article.get('description', '')
                        source = article.get('source', {}).get('name', 'æœªçŸ¥æ¥æº')
                        url = article.get('url', '')
                        published = article.get('publishedAt', '')
                        
                        news_str += f"### {i}. {title}\n\n"
                        news_str += f"**æ¥æº**: {source} | **æ—¶é—´**: {published}\n\n"
                        if description:
                            news_str += f"{description}\n\n"
                        if url:
                            news_str += f"**é“¾æ¥**: {url}\n\n"
                        news_str += "---\n\n"
                    
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… NewsAPIæ•°å­—è´§å¸æ–°é—»è·å–æˆåŠŸ: {len(articles)} æ¡")
                    return self._format_news_result(news_str, f"NewsAPIæ•°å­—è´§å¸æ–°é—»({crypto_name_cn})", model_info)
                else:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ NewsAPIæœªè¿”å›æ–°é—»")
            else:
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] â„¹ï¸ NewsAPIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡æ­¤æ–°é—»æº")
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] NewsAPIæ•°å­—è´§å¸æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ========== ä¼˜å…ˆçº§4: Redditï¼ˆç¤¾åŒºè®¨è®ºï¼‰ ==========
        try:
            if hasattr(self.toolkit, 'get_reddit_stock_info'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ… ä¼˜å…ˆçº§4: å°è¯•Redditæ•°å­—è´§å¸è®¨è®º...")
                
                # Redditæœç´¢æ•°å­—è´§å¸ç›¸å…³è®¨è®º
                result = self.toolkit.get_reddit_stock_info.invoke({
                    "ticker": crypto_code,
                    "curr_date": curr_date
                })
                
                if result and len(result.strip()) > 100:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Redditæ•°å­—è´§å¸è®¨è®ºè·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, f"Redditæ•°å­—è´§å¸è®¨è®º({crypto_name_cn})", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Redditæ•°å­—è´§å¸è®¨è®ºè·å–å¤±è´¥: {e}")

        # ========== æ‰€æœ‰æ•°æ®æºå‡å¤±è´¥ ==========
        logger.error(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âŒ æ‰€æœ‰æ•°å­—è´§å¸æ–°é—»æºå‡ä¸å¯ç”¨")
        return f"""## ğŸ“° {crypto_name_cn} ({crypto_code}) æ–°é—»åˆ†æ

**çŠ¶æ€**ï¼šâŒ æ— æ³•è·å–æ•°å­—è´§å¸æ–°é—»æ•°æ®

**å°è¯•çš„æ•°æ®æº**ï¼š
1. âŒ Google News
2. âŒ OpenAI å…¨çƒæ–°é—»
3. âŒ NewsAPIï¼ˆ{'å·²é…ç½®' if os.getenv('NEWSAPI_KEY') else 'æœªé…ç½®'}ï¼‰
4. âŒ Reddit

**å»ºè®®**ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. å¦‚æœä½¿ç”¨NewsAPIï¼Œè¯·ç¡®ä¿å·²é…ç½® `NEWSAPI_KEY` ç¯å¢ƒå˜é‡
3. ç¨åé‡è¯•

**æ•°æ®æ¥æº**ï¼šå¤šæºèšåˆï¼ˆGoogle Newsã€OpenAIã€NewsAPIã€Redditï¼‰"""
    
    def _get_us_share_news(self, stock_code: str, max_news: int, model_info: str = "", current_date: str = None) -> str:
        """è·å–ç¾è‚¡æ–°é—»"""
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è·å–ç¾è‚¡ {stock_code} æ–°é—»")
        
        # è·å–å½“å‰æ—¥æœŸï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ†ææ—¶é—´ç‚¹ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸï¼‰
        if current_date:
            curr_date = current_date
        else:
            curr_date = datetime.now().strftime("%Y-%m-%d")
        
        # ä¼˜å…ˆçº§1: OpenAIå…¨çƒæ–°é—»
        try:
            if hasattr(self.toolkit, 'get_global_news_openai'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•OpenAIç¾è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_global_news_openai.invoke({"curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… OpenAIç¾è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "OpenAIç¾è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] OpenAIç¾è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: Googleæ–°é—»ï¼ˆè‹±æ–‡æœç´¢ï¼‰
        try:
            if hasattr(self.toolkit, 'get_google_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•Googleç¾è‚¡æ–°é—»...")
                query = f"{stock_code} stock news earnings financial"
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_google_news.invoke({"query": query, "curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleç¾è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "Googleç¾è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleç¾è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: FinnHubæ–°é—»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            if hasattr(self.toolkit, 'get_finnhub_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•FinnHubç¾è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_finnhub_news.invoke({"symbol": stock_code, "max_results": min(max_news, 50)})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… FinnHubç¾è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "FinnHubç¾è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] FinnHubç¾è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        return "âŒ æ— æ³•è·å–ç¾è‚¡æ–°é—»æ•°æ®ï¼Œæ‰€æœ‰æ–°é—»æºå‡ä¸å¯ç”¨"
    
    def _format_news_result(self, news_content: str, source: str, model_info: str = "") -> str:
        """æ ¼å¼åŒ–æ–°é—»ç»“æœ"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # ğŸ” æ¸…ç†HTMLæ ‡ç­¾ï¼ˆç‰¹åˆ«æ˜¯<em>æ ‡ç­¾ï¼‰
        news_content = self._clean_html_tags(news_content)

        # ğŸ” æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°æ¸…ç†åçš„æ–°é—»å†…å®¹
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“‹ æ¸…ç†åæ–°é—»å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦): {news_content[:500]}")
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“Š æ¸…ç†åå†…å®¹é•¿åº¦: {len(news_content)} å­—ç¬¦")
        
        # æ£€æµ‹æ˜¯å¦ä¸ºGoogle/Geminiæ¨¡å‹
        is_google_model = any(keyword in model_info.lower() for keyword in ['google', 'gemini', 'gemma'])
        original_length = len(news_content)
        google_control_applied = False
        
        # ğŸ” æ·»åŠ Googleæ¨¡å‹æ£€æµ‹æ—¥å¿—
        if is_google_model:
            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ¤– æ£€æµ‹åˆ°Googleæ¨¡å‹ï¼Œå¯ç”¨ç‰¹æ®Šå¤„ç†")
        
        # å¯¹Googleæ¨¡å‹è¿›è¡Œç‰¹æ®Šçš„é•¿åº¦æ§åˆ¶
        if is_google_model and len(news_content) > 5000:  # é™ä½é˜ˆå€¼åˆ°5000å­—ç¬¦
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ”§ æ£€æµ‹åˆ°Googleæ¨¡å‹ï¼Œæ–°é—»å†…å®¹è¿‡é•¿({len(news_content)}å­—ç¬¦)ï¼Œè¿›è¡Œé•¿åº¦æ§åˆ¶...")
            
            # æ›´ä¸¥æ ¼çš„é•¿åº¦æ§åˆ¶ç­–ç•¥
            lines = news_content.split('\n')
            important_lines = []
            char_count = 0
            target_length = 3000  # ç›®æ ‡é•¿åº¦è®¾ä¸º3000å­—ç¬¦
            
            # ç¬¬ä¸€è½®ï¼šä¼˜å…ˆä¿ç•™åŒ…å«å…³é”®è¯çš„é‡è¦è¡Œ
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡è¦å…³é”®è¯
                important_keywords = ['è‚¡ç¥¨', 'å…¬å¸', 'è´¢æŠ¥', 'ä¸šç»©', 'æ¶¨è·Œ', 'ä»·æ ¼', 'å¸‚å€¼', 'è¥æ”¶', 'åˆ©æ¶¦', 
                                    'å¢é•¿', 'ä¸‹è·Œ', 'ä¸Šæ¶¨', 'ç›ˆåˆ©', 'äºæŸ', 'æŠ•èµ„', 'åˆ†æ', 'é¢„æœŸ', 'å…¬å‘Š']
                
                is_important = any(keyword in line for keyword in important_keywords)
                
                if is_important and char_count + len(line) < target_length:
                    important_lines.append(line)
                    char_count += len(line)
                elif not is_important and char_count + len(line) < target_length * 0.7:  # éé‡è¦å†…å®¹æ›´ä¸¥æ ¼é™åˆ¶
                    important_lines.append(line)
                    char_count += len(line)
                
                # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡é•¿åº¦ï¼Œåœæ­¢æ·»åŠ 
                if char_count >= target_length:
                    break
            
            # å¦‚æœæå–çš„é‡è¦å†…å®¹ä»ç„¶è¿‡é•¿ï¼Œè¿›è¡Œè¿›ä¸€æ­¥æˆªæ–­
            if important_lines:
                processed_content = '\n'.join(important_lines)
                if len(processed_content) > target_length:
                    processed_content = processed_content[:target_length] + "...(å†…å®¹å·²æ™ºèƒ½æˆªæ–­)"
                
                news_content = processed_content
                google_control_applied = True
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleæ¨¡å‹æ™ºèƒ½é•¿åº¦æ§åˆ¶å®Œæˆï¼Œä»{original_length}å­—ç¬¦å‹ç¼©è‡³{len(news_content)}å­—ç¬¦")
            else:
                # å¦‚æœæ²¡æœ‰é‡è¦è¡Œï¼Œç›´æ¥æˆªæ–­åˆ°ç›®æ ‡é•¿åº¦
                news_content = news_content[:target_length] + "...(å†…å®¹å·²å¼ºåˆ¶æˆªæ–­)"
                google_control_applied = True
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ Googleæ¨¡å‹å¼ºåˆ¶æˆªæ–­è‡³{target_length}å­—ç¬¦")
        
        # è®¡ç®—æœ€ç»ˆçš„æ ¼å¼åŒ–ç»“æœé•¿åº¦ï¼Œç¡®ä¿æ€»é•¿åº¦åˆç†
        base_format_length = 300  # æ ¼å¼åŒ–æ¨¡æ¿çš„å¤§æ¦‚é•¿åº¦
        if is_google_model and (len(news_content) + base_format_length) > 4000:
            # å¦‚æœåŠ ä¸Šæ ¼å¼åŒ–åä»ç„¶è¿‡é•¿ï¼Œè¿›ä¸€æ­¥å‹ç¼©æ–°é—»å†…å®¹
            max_content_length = 3500
            if len(news_content) > max_content_length:
                news_content = news_content[:max_content_length] + "...(å·²ä¼˜åŒ–é•¿åº¦)"
                google_control_applied = True
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ”§ Googleæ¨¡å‹æœ€ç»ˆé•¿åº¦ä¼˜åŒ–ï¼Œå†…å®¹é•¿åº¦: {len(news_content)}å­—ç¬¦")
        
        formatted_result = f"""
=== ğŸ“° æ–°é—»æ•°æ®æ¥æº: {source} ===
è·å–æ—¶é—´: {timestamp}
æ•°æ®é•¿åº¦: {len(news_content)} å­—ç¬¦
{f"æ¨¡å‹ç±»å‹: {model_info}" if model_info else ""}
{f"ğŸ”§ Googleæ¨¡å‹é•¿åº¦æ§åˆ¶å·²åº”ç”¨ (åŸé•¿åº¦: {original_length} å­—ç¬¦)" if google_control_applied else ""}

=== ğŸ“‹ æ–°é—»å†…å®¹ ===
{news_content}

=== âœ… æ•°æ®çŠ¶æ€ ===
çŠ¶æ€: æˆåŠŸè·å–
æ¥æº: {source}
æ—¶é—´æˆ³: {timestamp}
"""
        return formatted_result.strip()

    def _clean_html_tags(self, text: str) -> str:
        """æ¸…ç†HTMLæ ‡ç­¾ï¼Œç‰¹åˆ«æ˜¯<em>æ ‡ç­¾"""
        import re

        if not text:
            return text

        # ç§»é™¤ <em> å’Œ </em> æ ‡ç­¾ï¼ˆåªç§»é™¤æ ‡ç­¾ï¼Œä¸ç§»é™¤å†…å®¹ï¼‰
        text = re.sub(r'</?em[^>]*>', '', text, flags=re.IGNORECASE)

        # ç§»é™¤å…¶ä»–å¸¸è§çš„HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)

        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text).strip()

        return text


def create_unified_news_tool(toolkit):
    """åˆ›å»ºç»Ÿä¸€æ–°é—»å·¥å…·å‡½æ•°"""
    analyzer = UnifiedNewsAnalyzer(toolkit)
    
    def get_stock_news_unified(stock_code: str, max_news: int = 100, model_info: str = "", current_date: str = None):
        """
        ç»Ÿä¸€æ–°é—»è·å–å·¥å…·
        
        Args:
            stock_code (str): è‚¡ç¥¨ä»£ç  (æ”¯æŒAè‚¡å¦‚000001ã€æ¸¯è‚¡å¦‚0700.HKã€ç¾è‚¡å¦‚AAPL)
            max_news (int): æœ€å¤§æ–°é—»æ•°é‡ï¼Œé»˜è®¤100
            model_info (str): å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯ï¼Œç”¨äºç‰¹æ®Šå¤„ç†
            current_date (str): åˆ†ææ—¶é—´ç‚¹ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼Œåªè·å–è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æ–°é—»
        
        Returns:
            str: æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹
        """
        if not stock_code:
            return "âŒ é”™è¯¯: æœªæä¾›è‚¡ç¥¨ä»£ç "
        
        return analyzer.get_stock_news_unified(stock_code, max_news, model_info, current_date)
    
    # è®¾ç½®å·¥å…·å±æ€§
    get_stock_news_unified.name = "get_stock_news_unified"
    get_stock_news_unified.description = """
ç»Ÿä¸€æ–°é—»è·å–å·¥å…· - æ ¹æ®è‚¡ç¥¨ä»£ç è‡ªåŠ¨è·å–ç›¸åº”å¸‚åœºçš„æ–°é—»

åŠŸèƒ½:
- è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡/æ¸¯è‚¡/ç¾è‚¡ï¼‰
- æ ¹æ®è‚¡ç¥¨ç±»å‹é€‰æ‹©æœ€ä½³æ–°é—»æº
- Aè‚¡: ä¼˜å…ˆæ•°æ®åº“ç¼“å­˜ -> ä¸œæ–¹è´¢å¯Œ -> Googleä¸­æ–‡ -> OpenAI
- æ¸¯è‚¡: ä¼˜å…ˆGoogle -> OpenAI -> å®æ—¶æ–°é—»
- ç¾è‚¡: ä¼˜å…ˆOpenAI -> Googleè‹±æ–‡ -> FinnHub
- è¿”å›æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹
- æ”¯æŒGoogleæ¨¡å‹çš„ç‰¹æ®Šé•¿åº¦æ§åˆ¶
- å¦‚æœæä¾›äº† current_date å‚æ•°ï¼Œåªè·å–è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æ–°é—»ï¼ˆç”¨äºå†å²åˆ†æï¼‰

å‚æ•°:
- stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¿…éœ€ï¼‰
- max_news: æœ€å¤§æ–°é—»æ•°é‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤100ï¼‰
- model_info: æ¨¡å‹ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œç”¨äºç‰¹æ®Šå¤„ç†ï¼‰
- current_date: åˆ†ææ—¶é—´ç‚¹ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åªè·å–è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„æ–°é—»ï¼‰
"""
    
    return get_stock_news_unified